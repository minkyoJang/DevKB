{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1차시 : 리스트 순회하기 & 문자열 인덱싱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장의 단어를 하나씩 가져오기\n",
    "+ for 반복문에 in 키워드를 이용하면 리스트의 원소를 하나씩 가져와 변수에 저장할 수 있습니다.\n",
    "\n",
    "+ 여기에 리스트의 길이를 구하는 len()와, 연속된 정수를 만들어주는 range() 함수를 함께 사용하면 원소의 인덱스를 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java\n",
      "C\n",
      "Python\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> langs = ['Java', 'C','Python']\n",
    ">>> for lang in langs: \n",
    "        print(lang)\n",
    "'Java'\n",
    "'C'\n",
    "'Python'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "lower(), replace() 등 다양한 메소드를 이용해 트럼프 대통령의 트윗을 정제하기 위해선 먼저 리스트에 담긴 요소를 하나씩 가져와야 합니다.\n",
    "\n",
    "trump_tweets 리스트의 문자열 요소를 하나씩 가져와서 트윗 게시일과 함께 출력하는 date_tweet 함수를 살펴보고, 실행·제출해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018년 1월 1일: Will be leaving Florida for Washington (D.C.) today at 4:00 P.M. Much work to be done, but it will be a great New Year!\n",
      "2018년 1월 2일: Companies are giving big bonuses to their workers because of the Tax Cut Bill. Really great!\n",
      "2018년 1월 3일: MAKE AMERICA GREAT AGAIN!\n"
     ]
    }
   ],
   "source": [
    "# 트럼프 대통령의 1월 1~3일 트윗을 각각 리스트의 원소로 저장합니다.\n",
    "trump_tweets = [\n",
    "    'Will be leaving Florida for Washington (D.C.) today at 4:00 P.M. Much work to be done, but it will be a great New Year!',\n",
    "    'Companies are giving big bonuses to their workers because of the Tax Cut Bill. Really great!',\n",
    "    'MAKE AMERICA GREAT AGAIN!'\n",
    "]\n",
    "\n",
    "def date_tweet(tweet):\n",
    "    # index에 0~2을 차례대로 저장하여 반복문을 실행합니다.\n",
    "    for index in range(len(tweet)):\n",
    "        print('2018년 1월 ' + str(index+1) + '일: ' + tweet[index])\n",
    "\n",
    "\n",
    "# 실행 결과를 확인하기 위한 코드입니다.\n",
    "date_tweet(trump_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어의 일부분 가져오기\n",
    "+ 인덱스를 이용하면 문자열 또는 리스트의 특정 요소에 접근할 수 있습니다. 인덱스는 0부터 시작하며 -1은 맨 마지막 문자 또는 요소를 가리킵니다.\n",
    "\n",
    "+ 시작 인덱스와 끝 인덱스를 이용하면 특정 구간의 요소를 리스트형으로 접근할 수 있습니다. 끝 인덱스를 생략하면 시작 인덱스부터 마지막 요소까지 접근합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n",
      "P\n",
      "['C', 'Python']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C', 'Python']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> langs = ['Java', 'C','Python']\n",
    ">>> print(langs[-1])\n",
    "'Python'\n",
    ">>> print(langs[-1][0])\n",
    "'P'\n",
    ">>> print(langs[1:])\n",
    "['C', 'Python']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "문자열로 이루어진 text 리스트에서 k로 시작하는 문자열을 모두 출력하는 print_korea() 함수를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korea\n"
     ]
    }
   ],
   "source": [
    "# 트럼프 대통령 트윗을 공백 기준으로 분리한 리스트입니다. 수정하지 마세요.\n",
    "trump_tweets = ['thank', 'you', 'to', 'president', 'moon', 'of', 'south', 'korea', 'for', 'the', 'beautiful', 'welcoming', 'ceremony', 'it', 'will', 'always', 'be', 'remembered']\n",
    "\n",
    "def print_korea(text):\n",
    "    for i in text:\n",
    "        if i[0]=='k':\n",
    "            print(i)    \n",
    "    \n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "print_korea(trump_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2차시 : 문자열 함수 : startswith(), split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어의 첫 글자 확인하기\n",
    "+ startswith() 메소드를 이용하면 단어가 특정 문자열로 시작하는지 쉽게 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> 'Naver Cafe'.startswith('Naver')\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> 'Kakao Taxi'.startswith('Naver')\n",
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "해시태그와 멘션을 찾기 위서는 문자열이 # 또는 @로 시작하는지 확인해야 합니다.\n",
    "\n",
    "startswith() 메소드를 사용하여 앞서 인덱싱을 이용해 작성한 print_korea() 함수를 다시 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korea\n"
     ]
    }
   ],
   "source": [
    "# 트럼프 대통령 트윗을 공백 기준으로 분리한 리스트입니다. 수정하지 마세요.\n",
    "trump_tweets = ['thank', 'you', 'to', 'president', 'moon', 'of', 'south', 'korea', 'for', 'the', 'beautiful', 'welcoming', 'ceremony', 'it', 'will', 'always', 'be', 'remembered']\n",
    "\n",
    "def print_korea(tweet):\n",
    "    '''\n",
    "    문자열로 구성된 리스트에서 k로 시작하는 문자열을 출력합니다.\n",
    "    '''\n",
    "    for i in tweet:\n",
    "        if (i.startswith('k')):\n",
    "            print(i)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "print_korea(trump_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장을 단어 단위로 구분하기\n",
    "+ split() 메소드는 특정 문자를 기준으로 문자열을 분리합니다. 입력값을 넣지 않을 경우 공백을 기준으로 분리합니다. 분리된 문자열은 리스트의 원소로 저장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', ' Java', ' C']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Python', 'Java', 'C']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> langs = 'Python, Java, C'.split(',')\n",
    ">>> print(langs)\n",
    "['Python', 'Java', 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Make', 'America', 'Great', 'Again']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> 'Make America Great Again'.split()\n",
    "['Make', 'America', 'Great', 'Again']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "트윗에 사용된 단어를 하나씩 살펴보기 위해서는 문자열을 리스트로 변환해야 합니다.\n",
    "\n",
    "trump_tweet을 공백을 기준으로 분리하고 리스트형으로 반환하는 break_into_words() 함수를 수정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thank', 'you', 'to', 'president', 'moon', 'of', 'south', 'korea', 'for', 'the', 'beautiful', 'welcoming', 'ceremony', 'it', 'will', 'always', 'be', 'remembered']\n"
     ]
    }
   ],
   "source": [
    "# 트럼프 대통령의 트윗으로 구성된 문자열입니다. 수정하지 마세요. \n",
    "trump_tweets = \"thank you to president moon of south korea for the beautiful welcoming ceremony it will always be remembered\"\n",
    "\n",
    "def break_into_words(text):\n",
    "    words = text.split( )    \n",
    "    return words\n",
    "\n",
    "\n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "print(break_into_words(trump_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3차시 : 문자열 함수 : startswith(), split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 단어 추가하기\n",
    "+ append()는 리스트를 다룰 때 사용되는 가장 기본적인 메소드로, 리스트의 맨 마지막에 새로운 요소를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python', 'Java', 'C', 'JavaScript']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> langs = ['Python', 'Java', 'C']\n",
    ">>> langs.append('JavaScript')\n",
    "['Python', 'Java', 'C', 'JavaScript']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "append()를 이용하면 빈 리스트에 데이터를 쉽게 추가할 수 있습니다.\n",
    "\n",
    "trump_tweets 리스트에서 b로 시작하는 요소를 빈 리스트 new_list에 저장하는 make_new_list() 함수를 수정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['back', 'back', 'bigger', 'better', 'before']\n"
     ]
    }
   ],
   "source": [
    "# 트럼프 대통령 트윗을 공백 기준으로 분리한 리스트입니다. 수정하지 마세요.\n",
    "trump_tweets = ['america', 'is', 'back', 'and', 'we', 'are', 'coming', 'back', 'bigger', 'and', 'better', 'and', 'stronger', 'than', 'ever', 'before']\n",
    "\n",
    "def make_new_list(text):\n",
    "    # 아래 코드를 작성하세요.\n",
    "    new_list=[]\n",
    "    for i in text:\n",
    "        if i.startswith('b'):\n",
    "            new_list.append(i)\n",
    "    return new_list\n",
    "\n",
    "\n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "new_list = make_new_list(trump_tweets)\n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대소문자 변환하기\n",
    "+ lower(), upper() 메소드를 이용하면 문자열을 쉽게 소문자 또는 대문자로 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-087a27ce8e18>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-087a27ce8e18>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    >>>'elice'\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ">>> print('Elice'.lower())\n",
    ">>>'elice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-e595c5bbbde7>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-e595c5bbbde7>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    >>>'ELICE'\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ">>> print('Elice'.upper())\n",
    ">>>'ELICE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "가짜 뉴스를 뜻하는 Fake News는 트럼프 대통령이 가장 자주 사용하는 말 중 하나입니다.\n",
    "\n",
    "FAKE NEWS, Fake News는 대소문자가 다르기 때문에 두 단어가 몇 번 사용되었는지 정확하게 확인하기 위해서는 모두 소문자로 변환해야 합니다.\n",
    "\n",
    "trump_tweets 리스트의 문자열 요소를 모두 소문자로 변환하는 lowercase_all_characters() 함수를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake news - a total political witch hunt!\n",
      "any negative polls are fake news, just like the cnn, abc, nbc polls in the election.\n",
      "the fake news media is officially out of control.\n"
     ]
    }
   ],
   "source": [
    "# 트럼프 대통령의 트윗 세개로 구성된 리스트입니다. 수정하지 마세요.\n",
    "trump_tweets = [\n",
    "    \"FAKE NEWS - A TOTAL POLITICAL WITCH HUNT!\",\n",
    "    \"Any negative polls are fake news, just like the CNN, ABC, NBC polls in the election.\",\n",
    "    \"The Fake News media is officially out of control.\",\n",
    "]\n",
    " \n",
    "def lowercase_all_characters(text):\n",
    "    processed_text = []\n",
    "    # 아래 코드를 작성하세요.\n",
    "    for i in text:\n",
    "        processed_text.append(i.lower())\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "print('\\n'.join(lowercase_all_characters(trump_tweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4차시 : 문자열 함수 : replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특수기호 삭제하기\n",
    "+ replace() 메소드는 문자열에서 특정 문자나 문자열을 다른 문자(열)로 변경할 때 사용됩니다.\n",
    "\n",
    "+ replace()는 변경하고 싶은 문자열을 첫번째 입력값으로, 대체할 문자열을 두번째 입력값으로 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> '안녕하세요~!'.replace('~!', '.')\n",
    "'안녕하세요.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elice'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> '/* elice */'.replace('/', '').replace('*', '').replace(' ', '')\n",
    "'elice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "소문자로 변환된 trump_tweets의 트윗을 공백을 기준으로 구분할 경우 christmas', christmas,, christmas!!!가 생성되기 때문에 christmas가 몇 번 사용되었는지 정확하게 확인하기 위해서는 특수문자를 제거해야 합니다.\n",
    "\n",
    "trump_tweets 리스트의 문자열 요소에서 쉼표, 작은따옴표, 느낌표를 제거하는 remove_special_characters() 함수를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i hope everyone is having a great christmas then tomorrow it’s back to work in order to make america great again.\n",
      "7 of 10 americans prefer merry christmas over happy holidays.\n",
      "merry christmas\n"
     ]
    }
   ],
   "source": [
    "# 트럼프 대통령의 트윗 세개로 구성된 리스트입니다. 수정하지 마세요.\n",
    "trump_tweets = [\n",
    "    \"i hope everyone is having a great christmas, then tomorrow it’s back to work in order to make america great again.\",\n",
    "    \"7 of 10 americans prefer 'merry christmas' over 'happy holidays'.\",\n",
    "    \"merry christmas!!!\",\n",
    "]\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    processed_text = []\n",
    "    # 아래 코드를 작성하세요.\n",
    "    for i in text:\n",
    "        j = i.replace(',','').replace('!','').replace(\"'\",\"\")\n",
    "        processed_text.append(j)\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "print('\\n'.join(remove_special_characters(trump_tweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5차시 : 파일 & 데이터 구조 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 열고 읽기\n",
    "+ open()을 이용하면 지정한 파일 이름에 해당하는 파일을 열고, 읽거나 수정할 수 있습니다.\n",
    "\n",
    "+ 여기에 with ... as을 사용하면 파일을 자동으로 닫을 수 있고, for문을 사용하면 파일 내용을 한 줄씩 읽을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'filename.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d0808f140f84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'filename.txt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'filename.txt'"
     ]
    }
   ],
   "source": [
    ">>> with open('filename.txt') as file:\n",
    "       for line in file:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "영어 단어 데이터를 분석하려면, 먼저 데이터 저장된 파일을 파이썬으로 읽어 와야 합니다.\n",
    "\n",
    "파일의 내용을 각 줄의 번호와 함께 출력하는 print_lines() 함수를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 zoo,768\n",
      "\n",
      "2 zones,1168\n",
      "\n",
      "3 zone,2553\n",
      "\n",
      "4 zimbabwe,658\n",
      "\n",
      "5 zero,2286\n",
      "\n",
      "6 zealand,2636\n",
      "\n",
      "7 zambia,732\n",
      "\n",
      "8 yugoslavia,1400\n",
      "\n",
      "9 youths,914\n",
      "\n",
      "10 youth,5415\n",
      "\n",
      "11 yourself,10746\n",
      "\n",
      "12 yours,4241\n",
      "\n",
      "13 your,138337\n",
      "\n",
      "14 youngsters,1749\n",
      "\n",
      "15 youngest,1204\n",
      "\n",
      "16 younger,5403\n",
      "\n",
      "17 young,33611\n",
      "\n",
      "18 you,695595\n",
      "\n",
      "19 yorkshire,4393\n",
      "\n",
      "20 york,9906\n",
      "\n",
      "21 yo,1206\n",
      "\n",
      "22 yields,940\n",
      "\n",
      "23 yield,2113\n",
      "\n",
      "24 yet,33752\n",
      "\n",
      "25 yesterday,19507\n",
      "\n",
      "26 yes,60612\n",
      "\n",
      "27 yer,1509\n",
      "\n",
      "28 yep,1317\n",
      "\n",
      "29 yeltsin,1192\n",
      "\n",
      "30 yellow,4557\n",
      "\n",
      "31 yelled,754\n",
      "\n",
      "32 years,90224\n",
      "\n",
      "33 year,73778\n",
      "\n",
      "34 yeah,83382\n",
      "\n",
      "35 ye,1700\n",
      "\n",
      "36 yarn,877\n",
      "\n",
      "37 yards,3678\n",
      "\n",
      "38 yard,3267\n",
      "\n",
      "39 yacht,1033\n",
      "\n",
      "40 ya,1753\n",
      "\n",
      "41 wycliffe,716\n",
      "\n",
      "42 wrote,9909\n",
      "\n",
      "43 wrong,16080\n",
      "\n",
      "44 written,13675\n",
      "\n",
      "45 writings,1063\n",
      "\n",
      "46 writing,11582\n",
      "\n",
      "47 writes,2607\n",
      "\n",
      "48 writers,3581\n",
      "\n",
      "49 writer,3742\n",
      "\n",
      "50 write,10882\n",
      "\n",
      "51 wrist,1056\n",
      "\n",
      "52 wright,1972\n",
      "\n",
      "53 wrapped,1723\n",
      "\n",
      "54 wounds,1025\n",
      "\n",
      "55 wounded,1692\n",
      "\n",
      "56 wound,2161\n",
      "\n",
      "57 would,255198\n",
      "\n",
      "58 worthy,1403\n",
      "\n",
      "59 worthwhile,1484\n",
      "\n",
      "60 worth,12375\n",
      "\n",
      "61 worst,4817\n",
      "\n",
      "62 worship,1625\n",
      "\n",
      "63 worse,7237\n",
      "\n",
      "64 worrying,1473\n",
      "\n",
      "65 worry,5585\n",
      "\n",
      "66 worries,1308\n",
      "\n",
      "67 worried,4594\n",
      "\n",
      "68 worn,2099\n",
      "\n",
      "69 worms,678\n",
      "\n",
      "70 worldwide,2211\n",
      "\n",
      "71 worlds,1068\n",
      "\n",
      "72 world,59031\n",
      "\n",
      "73 workstations,809\n",
      "\n",
      "74 workstation,742\n",
      "\n",
      "75 workshops,1405\n",
      "\n",
      "76 workshop,1814\n",
      "\n",
      "77 works,14528\n",
      "\n",
      "78 workplace,846\n",
      "\n",
      "79 workings,733\n",
      "\n",
      "80 working-class,1900\n",
      "\n",
      "81 working,29252\n",
      "\n",
      "82 workforce,1530\n",
      "\n",
      "83 workers,14724\n",
      "\n",
      "84 worker,3635\n",
      "\n",
      "85 worked,12748\n",
      "\n",
      "86 work,91354\n",
      "\n",
      "87 wore,3011\n",
      "\n",
      "88 wordsworth,905\n",
      "\n",
      "89 words,24444\n",
      "\n",
      "90 wording,822\n",
      "\n",
      "91 word,19379\n",
      "\n",
      "92 worcester,737\n",
      "\n",
      "93 wool,1783\n",
      "\n",
      "94 woods,2135\n",
      "\n",
      "95 woodland,1025\n",
      "\n",
      "96 wooden,3547\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 파일을 불러옵니다.\n",
    "filename = 'corpus.txt'\n",
    "\n",
    "def print_lines(filename) :\n",
    "    with open(filename) as file:\n",
    "        line_number = 1\n",
    "        for line in file:\n",
    "            print(str(line_number)+' '+line)\n",
    "            line_number = line_number+1\n",
    "\n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "print_lines(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 형태 변환하기\n",
    "+ 튜플(tuple)은 리스트와 비슷한 데이터 구조로, 여러 값을 모아서 저장할 수 있습니다. 단, 리스트와 다르게 () 안에 요소가 입력되며 한 번 생성한 튜플은 그 값을 변경할 수 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> num_list = [1, 2]\n",
    ">>> num_list[1] = 3\n",
    ">>> print(num_list) \n",
    "[1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f69a1934ede0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_tuple\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnum_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;34m\"TypeError: 'tuple' object does not support item assignment\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    ">>> num_tuple = (1, 2)\n",
    ">>> num_tuple[1] = 3\n",
    "\"TypeError: 'tuple' object does not support item assignment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "corpus.txt의 내용을 읽고 (단어, 빈도수) 튜플로 구성된 리스트를 리턴하는 import_as_tuple() 함수를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('zoo', '768'), ('zones', '1168'), ('zone', '2553'), ('zimbabwe', '658'), ('zero', '2286'), ('zealand', '2636'), ('zambia', '732'), ('yugoslavia', '1400'), ('youths', '914'), ('youth', '5415'), ('yourself', '10746'), ('yours', '4241'), ('your', '138337'), ('youngsters', '1749'), ('youngest', '1204'), ('younger', '5403'), ('young', '33611'), ('you', '695595'), ('yorkshire', '4393'), ('york', '9906'), ('yo', '1206'), ('yields', '940'), ('yield', '2113'), ('yet', '33752'), ('yesterday', '19507'), ('yes', '60612'), ('yer', '1509'), ('yep', '1317'), ('yeltsin', '1192'), ('yellow', '4557'), ('yelled', '754'), ('years', '90224'), ('year', '73778'), ('yeah', '83382'), ('ye', '1700'), ('yarn', '877'), ('yards', '3678'), ('yard', '3267'), ('yacht', '1033'), ('ya', '1753'), ('wycliffe', '716'), ('wrote', '9909'), ('wrong', '16080'), ('written', '13675'), ('writings', '1063'), ('writing', '11582'), ('writes', '2607'), ('writers', '3581'), ('writer', '3742'), ('write', '10882'), ('wrist', '1056'), ('wright', '1972'), ('wrapped', '1723'), ('wounds', '1025'), ('wounded', '1692'), ('wound', '2161'), ('would', '255198'), ('worthy', '1403'), ('worthwhile', '1484'), ('worth', '12375'), ('worst', '4817'), ('worship', '1625'), ('worse', '7237'), ('worrying', '1473'), ('worry', '5585'), ('worries', '1308'), ('worried', '4594'), ('worn', '2099'), ('worms', '678'), ('worldwide', '2211'), ('worlds', '1068'), ('world', '59031'), ('workstations', '809'), ('workstation', '742'), ('workshops', '1405'), ('workshop', '1814'), ('works', '14528'), ('workplace', '846'), ('workings', '733'), ('working-class', '1900'), ('working', '29252'), ('workforce', '1530'), ('workers', '14724'), ('worker', '3635'), ('worked', '12748'), ('work', '91354'), ('wore', '3011'), ('wordsworth', '905'), ('words', '24444'), ('wording', '822'), ('word', '19379'), ('worcester', '737'), ('wool', '1783'), ('woods', '2135'), ('woodland', '1025'), ('wooden', '3547')]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 파일을 불러옵니다.\n",
    "filename = 'corpus.txt'\n",
    "\n",
    "def import_as_tuple(filename):\n",
    "    tuples = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            line2 = line.strip().split(',')\n",
    "            word = line2[0]\n",
    "            freq = line2[1]\n",
    "            new_tuples = (word, freq)\n",
    "            tuples.append(new_tuples)\n",
    "        return tuples\n",
    "\n",
    "\n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "print(import_as_tuple(filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6차시 : 리스트로 리스트 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한 줄 명령어로 데이터 다루기\n",
    "+ 파이썬의 가장 큰 장점 중 하나는 간결한 코드입니다. for문을 리스트 안에 입력하면 새로운 리스트를 코드 한 줄로 간결하게 생성할 수 있습니다. 아래의 두 코드는 동일하게 작동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> nums = [1, 2, 3]\n",
    ">>> new_nums = [n + 1 for n in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> nums = [1, 2, 3]\n",
    ">>> new_nums = []\n",
    ">>> for n in nums:\n",
    "        new_nums.append(n + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-3c82930e4aa8>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-31-3c82930e4aa8>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    >>> nums = [1, 2, 3, 4]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# for와 if를 함께 사용하면 리스트의 특정 원소만 선택하여 리스트에 추가할 수도 있습니다.\n",
    "\n",
    ">>> nums = [1, 2, 3, 4]\n",
    ">>> even_nums = [n for n in nums if n % 2 == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "None을 삭제하고 단어 모음 words에서 prefix로 시작하는 단어로만 이루어진 리스트를 리턴하는 filter_by_prefix 함수를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'alpha']\n"
     ]
    }
   ],
   "source": [
    "# 단어 모음을 선언합니다. 수정하지 마세요.\n",
    "words = [\n",
    "    'apple',\n",
    "    'banana',\n",
    "    'alpha',\n",
    "    'bravo',\n",
    "    'cherry',\n",
    "    'charlie',\n",
    "]\n",
    "\n",
    "def filter_by_prefix(words, prefix):\n",
    "    # 아래 코드를 작성하세요.\n",
    "    # content = []\n",
    "    # for n in words:\n",
    "    #    if n[0] == prefix :\n",
    "    #        content.append(n)\n",
    "    content = [n for n in words if n[0]==prefix]\n",
    "    return content\n",
    "\n",
    "\n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "a_words = filter_by_prefix(words, 'a')\n",
    "print(a_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7차시 : 데이터 정렬하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 정렬하기\n",
    "+ sorted()를 활용하면 리스트를 특정 기준에 맞춰 정렬할 수 있습니다. 이때 기준은 key에 저장한 함수를 따르게 됩니다.\n",
    "\n",
    "+ 아래의 코드는 숫자의 리스트를 절댓값을 기준으로 정렬합니다. 여기서 abs() 함수는 절댓값을 리턴하는 파이썬 내장 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, -3, -4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, -3, -4]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> new_nums = sorted([-4, 1, -3], key=abs)\n",
    ">>> print(new_nums)\n",
    "[1, -3, -4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "단어의 사용 빈도를 쉽게 확인하기 위해서는 단어를 빈도 순서대로 정렬해야 합니다.\n",
    "\n",
    "None을 삭제하고 이 작업에 필요한 함수 get_freq()와 sort_by_frequency() 함수를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('turbo', 1), ('time', 8), ('the', 15)]\n"
     ]
    }
   ],
   "source": [
    "# 단어어 해당 단어의 빈도수를 담은 리스트를 선언합니다. 수정하지 마세요.\n",
    "pairs = [\n",
    "    ('time', 8),\n",
    "    ('the', 15),\n",
    "    ('turbo', 1),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#(단어, 빈도수) 쌍으로 이루어진 튜플을 받아, 빈도수를 리턴합니다.    \n",
    "def get_freq(pair):\n",
    "    return pair[1]\n",
    "\n",
    "\n",
    "\n",
    "#(단어, 빈도수) 꼴 튜플의 리스트를 받아, 빈도수가 낮은 순서대로 정렬하여 리턴합니다.\n",
    "def sort_by_frequency(pairs):\n",
    "    return sorted(pairs, key = get_freq)\n",
    "\n",
    "\n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "print(sort_by_frequency(pairs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8차시 : 그래프 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차트 그리기\n",
    "+ 파이썬의 matplotlib 라이브러리를 이용하면 막대 차트, 꺾은선 차트 등 다양한 차트를 쉽게 그릴 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 응용하기\n",
    "영어 단어의 빈도수를 쉽게 비교하기 위해서는 한 눈에 들어오는 그래프를 그려야 합니다.\n",
    "\n",
    "matplotlib의 bar() 메소드를 이용하여 최근 평균 기온 그래프를 간단히 그려 보겠습니다. 코드와 주석을 이해한 후 출력된 차트를 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elice_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-46346f737ec6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 엘리스에서 차트를 그릴 때 필요한 라이브러리를 불러옵니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0melice_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEliceUtils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0melice_utils\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEliceUtils\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'elice_utils'"
     ]
    }
   ],
   "source": [
    "# matplotlib의 일부인 pyplot 라이브러리를 불러옵니다.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 엘리스에서 차트를 그릴 때 필요한 라이브러리를 불러옵니다.\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "# 월별 평균 기온을 선언합니다. 수정하지 마세요.\n",
    "years = [2013, 2014, 2015, 2016, 2017]\n",
    "temperatures = [5, 10, 15, 20, 17]\n",
    "\n",
    "#막대 차트를 출력합니다.   \n",
    "def draw_graph():\n",
    "    # 막대 그래프의 막대 위치를 결정하는 pos를 선언합니다.\n",
    "    pos = range(len(years))  # [0, 1, 2, 3, 4]\n",
    "    \n",
    "    # 높이가 온도인 막대 그래프를 그립니다.\n",
    "    # 각 막대를 가운데 정렬합니다.\n",
    "    plt.bar(pos, temperatures, align='center')\n",
    "    \n",
    "    # 각 막대에 해당되는 연도를 표기합니다.\n",
    "    plt.xticks(pos, years)\n",
    "    \n",
    "    # 그래프를 엘리스 플랫폼 상에 표시합니다.\n",
    "    plt.savefig('graph.png')\n",
    "    elice_utils.send_image('graph.png')\n",
    "\n",
    "print('막대 차트를 출력합니다.')\n",
    "draw_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9차시 : 딕셔너리와 키"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 빠르게 탐색하기\n",
    "+ 딕셔너리(dictionary)는 키와 값이 키:값 형태로 이루어진 데이터 구조입니다.\n",
    "\n",
    "+ 키와 값이 쌍을 이루기 때문에 키를 이용해 값을 빠르게 찾아낼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키위\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'키위'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> eng_kor = {\n",
    "        'apple': '사과',\n",
    "        'melon': '멜론',\n",
    "        'kiwi': '키위'\n",
    "    }\n",
    ">>> print(eng_kor['kiwi'])\n",
    "'키위'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "리스트의 경우 kiwi의 뜻을 찾기 위해 모든 요소를 탐색해야 합니다. 책에서 원하는 단어를 찾을 때까지 한 장씩 넘기는 비효율적인 작업으로 약 100배 이상의 시간이 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키위\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'키위'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> eng_kor = [\n",
    "        ('apple', '사과'), \n",
    "        ('melon', '멜론'), \n",
    "        ('kiwi', '키위'),\n",
    "    ]\n",
    ">>> for eng, kor in eng_kor:\n",
    "        if eng == 'kiwi':\n",
    "            print(kor)\n",
    "'키위'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 이용하기\n",
    "사용자 번호: 작품 번호로 이루어진 netflix.txt을 읽고, 사용자 번호를 키로, 작품 번호를 값으로 하는 딕셔너리를 생성하는 make_dictionary() 함수를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-eb50d682cf99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# 아래 주석을 해제하고 결과를 확인해보세요.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-eb50d682cf99>\u001b[0m in \u001b[0;36mmake_dictionary\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;31m# 아래 코드를 작성하세요\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0muser_to_titles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# 텍스트 파일을 불러옵니다.\n",
    "source_file = \"netflix.txt\"\n",
    "\n",
    "def make_dictionary(filename):\n",
    "    user_to_titles = {}\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            # 아래 코드를 작성하세요\n",
    "            user, title = line.strip().split(\":\")\n",
    "            user_to_titles[user] = title\n",
    "            \n",
    "            \n",
    "        return user_to_titles\n",
    "\n",
    "\n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "print(make_dictionary(source_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 순회하기\n",
    "+ for문과 items() 메소드를 이용하면 딕셔너리의 모든 키와 값을 (키, 값)의 형태로 리스트에 담을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gunwoo gw\n",
      "harry hyhl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'harryhyhl'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> users = {'gunwoo':'gw', 'harry':'hyhl'}\n",
    ">>> for user, id in users.items():\n",
    "        print(user, id)\n",
    "'gunwoo' 'gw'\n",
    "'harry' 'hyhl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 이용하기\n",
    "딕셔너리로 변환한 데이터의 통계를 내기 위해서는 키와 값을 모두 불러와야 합니다. {사용자: [작품 리스트]} 형식으로 저장된 딕셔너리를 {사용자: 본 작품의 수}로 변환하는 함수를 작성하세요.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 3, 2: 4, 3: 1, 4: 7, 5: 5}\n"
     ]
    }
   ],
   "source": [
    "# 사용자가 시청한 작품의 리스트를 저장합니다. 수정하지 마세요. \n",
    "user_to_titles = {\n",
    "    1: [271, 318, 491],\n",
    "    2: [318, 19, 2980, 475],\n",
    "    3: [475],\n",
    "    4: [271, 318, 491, 2980, 19, 318, 475],\n",
    "    5: [882, 91, 2980, 557, 35],\n",
    "}\n",
    "def get_user_to_num_titles(user_to_titles):\n",
    "    user_to_num_titles = {}\n",
    "    \n",
    "    # 아래 함수를 완성하세요.\n",
    "    for key, value in user_to_titles.items():\n",
    "        user_to_num_titles[key] = len(value)\n",
    "    \n",
    "    \n",
    "    return user_to_num_titles\n",
    "    \n",
    "\n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "print(get_user_to_num_titles(user_to_titles))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10차시 : JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON 데이터 읽고 생성하기\n",
    "+ JSON(JavaScript Object Notation)과 파이썬의 딕셔너리는 모두 키:값이 쌍으로 이루어진 데이터 형식입니다. 파이썬의 json 패키지에 포함된 함수를 이용해 두 형식을 쉽게 변환할 수 있습니다.\n",
    "\n",
    "+ loads(): JSON 형태의 문자열을 딕셔너리로 변환합니다. 이 때 딕셔너리의 모든 원소는 문자열 타입으로 설정됩니다.\n",
    "+ dumps(): 딕셔너리를 JSON 형태의 문자열로 변환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에서 이용하기\n",
    "read()와 write() 메소드를 이용해 JSON 파일을 딕셔너리로 변환하여 리턴하는 함수 create_dict()와, 변환된 내용을 파일에 저장하는 create_json() 함수를 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Iron Man': 31928,\n",
       " 'Iron Man 2': 15293,\n",
       " 'Dark Knight': 42107,\n",
       " 'Man in Black': 20113}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# netflix.json\n",
    "{\n",
    "    \"Iron Man\": 31928,\n",
    "    \"Iron Man 2\": 15293,\n",
    "    \"Dark Knight\": 42107,\n",
    "    \"Man in Black\": 20113\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Iron Man': 3192,\n",
       " 'Iron Man 2': 1593,\n",
       " 'Dark Knight': 4207,\n",
       " 'Man in Black': 2113}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# src.json\n",
    "{\n",
    "    \"Iron Man\": 3192,\n",
    "    \"Iron Man 2\": 1593,\n",
    "    \"Dark Knight\": 4207,\n",
    "    \"Man in Black\": 2113\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'netflix.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-8486fb98edbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'new_netflix.json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mnetflix_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'원래 데이터: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetflix_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-8486fb98edbe>\u001b[0m in \u001b[0;36mcreate_dict\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#JSON 파일을 읽고 문자열을 딕셔너리로 변환합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mjson_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'netflix.json'"
     ]
    }
   ],
   "source": [
    "# json 패키지를 임포트합니다.\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "#JSON 파일을 읽고 문자열을 딕셔너리로 변환합니다.\n",
    "def create_dict(filename):\n",
    "    with open(filename) as file:\n",
    "        json_string = file.read()\n",
    "        result = json.loads(json_string)\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "#JSON 파일을 읽고 딕셔너리를 JSON 형태의 문자열로 변환합니다.\n",
    "def create_json(dictionary, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        # 함수를 완성하세요\n",
    "        data = json.dumps(dictionary)\n",
    "        file.write(data)\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        \n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "src = 'netflix.json'\n",
    "dst = 'new_netflix.json'\n",
    "\n",
    "netflix_dict = create_dict(src)\n",
    "print('원래 데이터: ' + str(netflix_dict))\n",
    "\n",
    "netflix_dict['Dark Knight'] = 39217\n",
    "create_json(netflix_dict, dst)\n",
    "updated_dict = create_dict(dst)\n",
    "print('수정된 데이터: ' + str(updated_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11차시 : 집합과 집합연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터의 집합 나타내기\n",
    "+ 파이썬의 set은 집합을 나타내는 데이터 구조입니다. 집합은 순서와 중복이 없는 데이터 구조로, 데이터 분석에서 중복을 무시해야 하는 경우에 사용할 수 있습니다.예로, 수강생 명단이 주어졌을 때 set을 이용하면 학생 유형을 쉽게 구할 수 있습니다.\n",
    "\n",
    "+ A 수업과 B 수업 둘 중 하나 이상을 수강하는 학생 수 구하기\n",
    "+ A 수업과 B 수업을 모두 수강하는 학생 수 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 이용하기\n",
    "작품 A와 B를 모두 시청한 사람의 수, 둘 중 하나만 시청한 사람의 수를 이용하면 두 작품의 유사도를 유추할 수 있습니다. 리스트와 딕셔너리 대신 집합을 사용하면 이를 훨씬 쉽게 구할 수 있습니다.\n",
    "\n",
    "집합을 생성하고 원소를 추가, 삭제하는 함수를 연습해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 3과 5를 원소로 갖는 새로운 집합을 생성합니다.\n",
    "my_set = {3,5}\n",
    "\n",
    "# 채점을 위한 코드입니다. 수정하지 마세요. \n",
    "submit1 = my_set.copy()\n",
    "\n",
    "# 정수 7을 my_set에 추가합니다.\n",
    "my_set.add(7)\n",
    "\n",
    "\n",
    "# 채점을 위한 코드입니다. 수정하지 마세요. \n",
    "submit2 = my_set.copy()\n",
    "\n",
    "# new_numbers 리스트의 원소를 my_set에 추가합니다.\n",
    "new_numbers = [1, 2, 3, 4, 5]\n",
    "my_set.update(new_numbers)\n",
    "\n",
    "\n",
    "# 채점을 위한 코드입니다. 수정하지 마세요. \n",
    "submit3 = my_set.copy()\n",
    "\n",
    "# my_set에서 짝수를 모두 제거합니다.\n",
    "my_set = {num for num in my_set if num % 2 != 0}\n",
    "\n",
    "\n",
    "# 채점을 위한 코드입니다. 수정하지 마세요. \n",
    "submit4 = my_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 집합 연산자\n",
    "+ 집합 연산자를 이용하면, 합집합, 교집합, 차집합 등의 집합 연산을 수행할 수 있습니다.\n",
    "\n",
    "+ 합집합: 두 집합 중 최소 하나에 속하는 원소들의 집합\n",
    "+ 교집합: 두 집합에 모두 속하는 원소들의 집합\n",
    "+ B에 대한 A의 차집합: A에는 속하지만 B에는 속하지 않는 원소들의 집합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에서 이용하기\n",
    "집합 연산을 이용하면 여러 작품의 시청자 통계를 쉽게 낼 수 있습니다.\n",
    "\n",
    "다크나이트와 아이언맨, 두 작품의 시청자에 관한 네 종류의 통계를 내보겠습니다. 집합 연산자와 len() 함수를 이용하여 다양한 통계를 내는 코드를 완성해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'viewers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-f585bf1a19a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 각 영화 별 시청자 리스트를 임포트합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mviewers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdark_knight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miron_man\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdark_knight_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdark_knight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0miron_man_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miron_man\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'viewers'"
     ]
    }
   ],
   "source": [
    "# 각 영화 별 시청자 리스트를 임포트합니다.\n",
    "from viewers import dark_knight, iron_man\n",
    "\n",
    "dark_knight_set = set(dark_knight)\n",
    "iron_man_set = set(iron_man)\n",
    "\n",
    "# 두 작품을 모두 시청한 사람의 수\n",
    "both = len(dark_knight_set & iron_man_set)\n",
    "\n",
    "# 두 작품 중 최소 하나를 시청한 사람의 수\n",
    "either = len(dark_knight_set | iron_man_set)\n",
    "\n",
    "# 다크나이트만 시청한 사람의 수\n",
    "dark_knight_only = len(dark_knight_set - iron_man_set)\n",
    "\n",
    "# 아이언맨만 시청한 사람의 수\n",
    "iron_man_only = len(iron_man_set - dark_knight_set)\n",
    "\n",
    "\n",
    "# 아래 주석을 해제하고 실행 결과를 확인해보세요.\n",
    "print(\"두 작품 모두 시청: {}명\".format(both))\n",
    "print(\"하나 이상 시청: {}명\".format(either))\n",
    "print(\"다크나이트만 시청: {}명\".format(dark_knight_only))\n",
    "print(\"아이언맨만 시청: {}명\".format(iron_man_only))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12차시 : matplotlib으로 그래프 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matplotlib으로 차트 설정하기\n",
    "+ 파이썬의 차트 라이브러리인 matploblib에 대해서 더 자세히 알아봅시다. matplotlib 라이브러리는 단순히 차트를 그리는 것뿐만 아니라, 차트에 더 많은 정보를 추가하고 보기 좋게 만드는 다양한 기능을 제공하고 있습니다.\n",
    "\n",
    "+ 한국어 표시를 위해 폰트 설정하기\n",
    "+ 차트의 제목 설정하기\n",
    "+ X축과 Y축에 라벨 표시하기\n",
    "+ 차트의 여백 조정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함께 따라하기\n",
    "작성된 코드는 이전에 나온 영어 단어 모음 분석하기 문제에서 사용했던 코드를 약간 수정한 것입니다.\n",
    "\n",
    "먼저 코드와 각 줄의 주석을 잘 읽고, 직접 실행해 보세요. 코드를 조금씩 수정하며, 차트의 모양이 변하는 것을 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elice_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-a07ca3553d22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfont_manager\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0melice_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEliceUtils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0melice_utils\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEliceUtils\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'elice_utils'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "# 날짜 별 온도 데이터를 세팅합니다.\n",
    "dates = [\"1월 {}일\".format(day) for day in range(1, 32)]\n",
    "temperatures = list(range(1, 32))\n",
    "\n",
    "# 막대 그래프의 막대 위치를 결정하는 pos를 선언합니다.\n",
    "pos = range(len(dates))\n",
    "\n",
    "# 한국어를 보기 좋게 표시할 수 있도록 폰트를 설정합니다.\n",
    "font = fm.FontProperties(fname='./NanumBarunGothic.ttf')\n",
    "\n",
    "# 막대의 높이가 빈도의 값이 되도록 설정합니다.\n",
    "plt.bar(pos, temperatures, align='center')\n",
    "\n",
    "# 각 막대에 해당되는 단어를 입력합니다.\n",
    "plt.xticks(pos, dates, rotation='vertical', fontproperties=font)\n",
    "\n",
    "# 그래프의 제목을 설정합니다.\n",
    "plt.title('1월 중 기온 변화', fontproperties=font)\n",
    "\n",
    "# Y축에 설명을 추가합니다.\n",
    "plt.ylabel('온도', fontproperties=font)\n",
    "\n",
    "# 단어가 잘리지 않도록 여백을 조정합니다.\n",
    "plt.tight_layout()\n",
    "\n",
    "# 그래프를 표시합니다.\n",
    "plt.savefig('graph.png')\n",
    "elice_utils.send_image('graph.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13차시 : CSV데이터 읽고 처리하기 - reader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV 데이터 읽고 처리하기\n",
    "+ CSV는 콤마로 나뉘어진 데이터 형식으로, 용량이 작고 엑셀 등의 프로그램으로 보기 좋게 표현할 수 있다는 장점이 있습니다. 파이썬의 내장 csv 라이브러리를 이용하면 CSV 파일을 효율적으로 읽어 올 수 있습니다.\n",
    "\n",
    "+ reader()는 CSV 파일의 내용을 먼저 줄 별로 나눈 뒤, 구분 기호(delimiter)를 기준으로 분리해 주는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-6d97cd0e59fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "reader = csv.reader(file, delimiter=',')\n",
    "for row in reader:\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에 이용하기\n",
    "CSV 데이터를 분석하려면, 먼저 각 열의 데이터를 분리해야 합니다. 책 정보가 담긴 CSV 파일의 데이터를 ,를 기준으로 분리하고 제목 (저자): 페이지 수p 형식으로 출력하는 함수를 완성하세요. (예: On the Origin of Species (Charles Darwin): 502p)\n",
    "\n",
    "books.csv 파일은 1열부터 제목, 저자, 장르, 페이지 수, 출판사 순서로 나열되어 있습니다. 먼저 파일을 열고 구조를 확인한 후 코딩을 시작하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundamentals of Wavelets (Goswami, Jaideva): 228p\n",
      "Data Smart (Foreman, John): 235p\n",
      "God Created the Integers (Hawking, Stephen): 197p\n",
      "Superfreakonomics (Dubner, Stephen): 179p\n",
      "Orientalism (Said, Edward): 197p\n",
      "Nature of Statistical Learning Theory, The (Vapnik, Vladimir): 230p\n",
      "Integration of the Indian States (Menon, V P): 217p\n",
      "Drunkard's Walk, The (Mlodinow, Leonard): 197p\n",
      "Image Processing & Mathematical Morphology (Shih, Frank): 241p\n",
      "How to Think Like Sherlock Holmes (Konnikova, Maria): 240p\n",
      "Data Scientists at Work (Sebastian Gutierrez): 230p\n",
      "Slaughterhouse Five (Vonnegut, Kurt): 198p\n",
      "Birth of a Theorem (Villani, Cedric): 234p\n",
      "Structure & Interpretation of Computer Programs (Sussman, Gerald): 240p\n",
      "Age of Wrath, The (Eraly, Abraham): 238p\n",
      "Trial, The (Kafka, Frank): 198p\n",
      "Statistical Decision Theory' (Pratt, John): 236p\n",
      "Data Mining Handbook (Nisbet, Robert): 242p\n",
      "New Machiavelli, The (Wells, H. G.): 180p\n",
      "Physics & Philosophy (Heisenberg, Werner): 197p\n",
      "Making Software (Oram, Andy): 232p\n",
      "Analysis, Vol I (Tao, Terence): 248p\n",
      "Machine Learning for Hackers (Conway, Drew): 233p\n",
      "Signal and the Noise, The (Silver, Nate): 233p\n",
      "Python for Data Analysis (McKinney, Wes): 233p\n",
      "Introduction to Algorithms (Cormen, Thomas): 234p\n",
      "Beautiful and the Damned, The (Deb, Siddhartha): 198p\n",
      "Outsider, The (Camus, Albert): 198p\n",
      "Complete Sherlock Holmes, The - Vol I (Doyle, Arthur Conan): 176p\n",
      "Complete Sherlock Holmes, The - Vol II (Doyle, Arthur Conan): 176p\n",
      "Wealth of Nations, The (Smith, Adam): 175p\n",
      "Pillars of the Earth, The (Follett, Ken): 176p\n",
      "Mein Kampf (Hitler, Adolf): 212p\n",
      "Tao of Physics, The (Capra, Fritjof): 179p\n",
      "Surely You're Joking Mr Feynman (Feynman, Richard): 198p\n",
      "Farewell to Arms, A (Hemingway, Ernest): 179p\n",
      "Veteran, The (Forsyth, Frederick): 177p\n",
      "False Impressions (Archer, Jeffery): 177p\n",
      "Last Lecture, The (Pausch, Randy): 197p\n",
      "Return of the Primitive (Rand, Ayn): 202p\n",
      "Jurassic Park (Crichton, Michael): 174p\n",
      "Russian Journal, A (Steinbeck, John): 196p\n",
      "Tales of Mystery and Imagination (Poe, Edgar Allen): 172p\n",
      "Freakonomics (Dubner, Stephen): 197p\n",
      "Hidden Connections, The (Capra, Fritjof): 197p\n",
      "Story of Philosophy, The (Durant, Will): 170p\n",
      "Asami Asami (Deshpande, P L): 205p\n",
      "Journal of a Novel (Steinbeck, John): 196p\n",
      "Once There Was a War (Steinbeck, John): 196p\n",
      "Moon is Down, The (Steinbeck, John): 196p\n",
      "Brethren, The (Grisham, John): 174p\n",
      "In a Free State (Naipaul, V. S.): 196p\n",
      "Catch 22 (Heller, Joseph): 178p\n",
      "Complete Mastermind, The (BBC): 178p\n",
      "Dylan on Dylan (Dylan, Bob): 197p\n",
      "Soft Computing & Intelligent Systems (Gupta, Madan): 242p\n",
      "Textbook of Economic Theory (Stonier, Alfred): 242p\n",
      "Econometric Analysis (Greene, W. H.): 242p\n",
      "Learning OpenCV (Bradsky, Gary): 232p\n",
      "Data Structures Using C & C++ (Tanenbaum, Andrew): 235p\n",
      "Computer Vision, A Modern Approach (Forsyth, David): 255p\n",
      "Principles of Communication Systems (Taub, Schilling): 240p\n",
      "Let Us C (Kanetkar, Yashwant): 213p\n",
      "Amulet of Samarkand, The (Stroud, Jonathan): 179p\n",
      "Crime and Punishment (Dostoevsky, Fyodor): 180p\n",
      "Angels & Demons (Brown, Dan): 178p\n",
      "Argumentative Indian, The (Sen, Amartya): 209p\n",
      "Sea of Poppies (Ghosh, Amitav): 197p\n",
      "Idea of Justice, The (Sen, Amartya): 212p\n",
      "Raisin in the Sun, A (Hansberry, Lorraine): 175p\n",
      "All the President's Men (Woodward, Bob): 177p\n",
      "Prisoner of Birth, A (Archer, Jeffery): 176p\n",
      "Scoop! (Nayar, Kuldip): 216p\n",
      "Ahe Manohar Tari (Deshpande, Sunita): 213p\n",
      "Last Mughal, The (Dalrymple, William): 199p\n",
      "Social Choice & Welfare, Vol 39 No. 1 (Various): 235p\n",
      "Radiowaril Bhashane & Shrutika (Deshpande, P L): 213p\n",
      "Gun Gayin Awadi (Deshpande, P L): 212p\n",
      "Aghal Paghal (Deshpande, P L): 212p\n",
      "Maqta-e-Ghalib (Garg, Sanjay): 221p\n",
      "Beyond Degrees (): 222p\n",
      "Manasa (Kale, V P): 213p\n",
      "India from Midnight to Milennium (Tharoor, Shashi): 198p\n",
      "World's Greatest Trials, The (): 210p\n",
      "Great Indian Novel, The (Tharoor, Shashi): 198p\n",
      "O Jerusalem! (Lapierre, Dominique): 217p\n",
      "City of Joy, The (Lapierre, Dominique): 177p\n",
      "Freedom at Midnight (Lapierre, Dominique): 167p\n",
      "Winter of Our Discontent, The (Steinbeck, John): 196p\n",
      "On Education (Russell, Bertrand): 203p\n",
      "Free Will (Harris, Sam): 203p\n",
      "Bookless in Baghdad (Tharoor, Shashi): 206p\n",
      "Case of the Lame Canary, The (Gardner, Earle Stanley): 179p\n",
      "Theory of Everything, The (Hawking, Stephen): 217p\n",
      "New Markets & Other Essays (Drucker, Peter): 176p\n",
      "Electric Universe (Bodanis, David): 201p\n",
      "Hunchback of Notre Dame, The (Hugo, Victor): 175p\n",
      "Burning Bright (Steinbeck, John): 175p\n",
      "Age of Discontuinity, The (Drucker, Peter): 178p\n",
      "Doctor in the Nude (Gordon, Richard): 179p\n",
      "Down and Out in Paris & London (Orwell, George): 179p\n",
      "Identity & Violence (Sen, Amartya): 219p\n",
      "Beyond the Three Seas (Dalrymple, William): 197p\n",
      "World's Greatest Short Stories, The (): 217p\n",
      "Talking Straight (Iacoca, Lee): 175p\n",
      "Maugham's Collected Short Stories, Vol 3 (Maugham, William S): 171p\n",
      "Phantom of Manhattan, The (Forsyth, Frederick): 180p\n",
      "Ashenden of The British Agent (Maugham, William S): 160p\n",
      "Zen & The Art of Motorcycle Maintenance (Pirsig, Robert): 172p\n",
      "Great War for Civilization, The (Fisk, Robert): 197p\n",
      "We the Living (Rand, Ayn): 178p\n",
      "Artist and the Mathematician, The (Aczel, Amir): 186p\n",
      "History of Western Philosophy (Russell, Bertrand): 213p\n",
      "Selected Short Stories (): 215p\n",
      "Rationality & Freedom (Sen, Amartya): 213p\n",
      "Clash of Civilizations and Remaking of the World Order (Huntington, Samuel): 228p\n",
      "Uncommon Wisdom (Capra, Fritjof): 197p\n",
      "One (Bach, Richard): 172p\n",
      "Karl Marx Biography (): 162p\n",
      "To Sir With Love (Braithwaite): 197p\n",
      "Half A Life (Naipaul, V S): 196p\n",
      "Discovery of India, The (Nehru, Jawaharlal): 230p\n",
      "Apulki (Deshpande, P L): 211p\n",
      "Unpopular Essays (Russell, Bertrand): 198p\n",
      "Deceiver, The (Forsyth, Frederick): 178p\n",
      "Veil: Secret Wars of the CIA (Woodward, Bob): 171p\n",
      "Char Shabda (Deshpande, P L): 214p\n",
      "Rosy is My Relative (Durrell, Gerald): 176p\n",
      "Moon and Sixpence, The (Maugham, William S): 180p\n",
      "Political Philosophers (): 162p\n",
      "Short History of the World, A (Wells, H G): 197p\n",
      "Trembling of a Leaf, The (Maugham, William S): 205p\n",
      "Doctor on the Brain (Gordon, Richard): 204p\n",
      "Simpsons & Their Mathematical Secrets (Singh, Simon): 233p\n",
      "Pattern Classification (Duda, Hart): 241p\n",
      "From Beirut to Jerusalem (Friedman, Thomas): 202p\n",
      "Code Book, The (Singh, Simon): 197p\n",
      "Age of the Warrior, The (Fisk, Robert): 197p\n",
      "Final Crisis (): 257p\n",
      "Killing Joke, The (): 283p\n",
      "Flashpoint (): 265p\n",
      "Batman Earth One (): 265p\n",
      "Crisis on Infinite Earths (): 258p\n",
      "Numbers Behind Numb3rs, The (Devlin, Keith): 202p\n",
      "Superman Earth One - 1 (): 259p\n",
      "Superman Earth One - 2 (): 258p\n",
      "Justice League: Throne of Atlantis (): 258p\n",
      "Justice League: The Villain's Journey (): 258p\n",
      "Death of Superman, The (): 258p\n",
      "History of the DC Universe (): 258p\n",
      "Batman: The Long Halloween (): 258p\n",
      "Life in Letters, A (Steinbeck, John): 196p\n",
      "Information, The (Gleick, James): 233p\n",
      "Journal of Economics, vol 106 No 3 (): 235p\n",
      "Elements of Information Theory (Thomas, Joy): 229p\n",
      "Power Electronics - Rashid (Rashid, Muhammad): 235p\n",
      "Power Electronics - Mohan (Mohan, Ned): 237p\n",
      "Neural Networks (Haykin, Simon): 240p\n",
      "Grapes of Wrath, The (Steinbeck, John): 196p\n",
      "Vyakti ani Valli (Deshpande, P L): 211p\n",
      "Statistical Learning Theory (Vapnik, Vladimir): 228p\n",
      "Empire of the Mughal - The Tainted Throne (Rutherford, Alex): 180p\n",
      "Empire of the Mughal - Brothers at War (Rutherford, Alex): 180p\n",
      "Empire of the Mughal - Ruler of the World (Rutherford, Alex): 180p\n",
      "Empire of the Mughal - The Serpent's Tooth (Rutherford, Alex): 180p\n",
      "Empire of the Mughal - Raiders from the North (Rutherford, Alex): 180p\n",
      "Mossad (Baz-Zohar, Michael): 236p\n",
      "Jim Corbett Omnibus (Corbett, Jim): 223p\n",
      "20000 Leagues Under the Sea (Verne, Jules): 190p\n",
      "Batatyachi Chal (Deshpande P L): 200p\n",
      "Hafasavnuk (Deshpande P L): 211p\n",
      "Urlasurla (Deshpande P L): 211p\n",
      "Pointers in C (Kanetkar, Yashwant): 213p\n",
      "Cathedral and the Bazaar, The (Raymond, Eric): 217p\n",
      "Design with OpAmps (Franco, Sergio): 240p\n",
      "Think Complexity (Downey, Allen): 230p\n",
      "Devil's Advocate, The (West, Morris): 178p\n",
      "Ayn Rand Answers (Rand, Ayn): 203p\n",
      "Philosophy: Who Needs It (Rand, Ayn): 171p\n",
      "World's Great Thinkers, The (): 189p\n",
      "Data Analysis with Open Source Tools (Janert, Phillip): 230p\n",
      "Broca's Brain (Sagan, Carl): 174p\n",
      "Men of Mathematics (Bell, E T): 217p\n",
      "Oxford book of Modern Science Writing (Dawkins, Richard): 240p\n",
      "Justice, Judiciary and Democracy (Ranjan, Sudhanshu): 224p\n",
      "Arthashastra, The (Kautiyla): 214p\n",
      "We the People (Palkhivala): 216p\n",
      "We the Nation (Palkhivala): 216p\n",
      "Courtroom Genius, The (Sorabjee): 217p\n",
      "Dongri to Dubai (Zaidi, Hussain): 216p\n",
      "History of England, Foundation (Ackroyd, Peter): 197p\n",
      "City of Djinns (Dalrymple, William): 198p\n",
      "India's Legal System (Nariman): 177p\n",
      "More Tears to Cry (Sassoon, Jean): 235p\n",
      "Ropemaker, The (Dickinson, Peter): 196p\n",
      "Angels & Demons (Brown, Dan): 170p\n",
      "Judge, The (): 170p\n",
      "Attorney, The (): 170p\n",
      "Prince, The (Machiavelli): 173p\n",
      "Eyeless in Gaza (Huxley, Aldous): 180p\n",
      "Tales of Beedle the Bard (Rowling, J K): 184p\n",
      "Girl with the Dragon Tattoo (Larsson, Steig): 179p\n",
      "Girl who kicked the Hornet's Nest (Larsson, Steig): 179p\n",
      "Girl who played with Fire (Larsson, Steig): 179p\n",
      "Batman Handbook (): 270p\n",
      "Murphy's Law (): 178p\n",
      "Structure and Randomness (Tao, Terence): 252p\n",
      "Image Processing with MATLAB (Eddins, Steve): 241p\n",
      "Animal Farm (Orwell, George): 180p\n",
      "Idiot, The (Dostoevsky, Fyodor): 197p\n",
      "Christmas Carol, A (Dickens, Charles): 196p\n"
     ]
    }
   ],
   "source": [
    "# csv 모듈을 임포트합니다. \n",
    "import csv\n",
    "\n",
    "def print_book_info(filename):\n",
    "    with open(filename) as file:\n",
    "        # ',' 기호로 분리된 CSV 파일을 처리하세요..\n",
    "        reader = csv.reader(file, delimiter= ',')\n",
    "        \n",
    "        # 처리된 파일의 각 줄을 불러옵니다.\n",
    "        for row in reader:\n",
    "            \n",
    "            # 함수를 완성하세요.\n",
    "            title = row[0]\n",
    "            author = row[1]\n",
    "            pages = row[3]\n",
    "            print(\"{} ({}): {}p\".format(title, author, pages))\n",
    "\n",
    "\n",
    "# 아래 주석을 해제하고 실행 결과를 확인해보세요.\n",
    "filename = 'books.csv'\n",
    "print_book_info(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV 데이터 변환하기\n",
    "+ CSV 데이터의 각 열은 고유한 의미를 갖습니다. 책 데이터를 CSV 형식으로 저장한다면 각 열은 제목, 작가, 페이지 수 등의 의미를 갖게 됩니다.\n",
    "\n",
    "+ 이 성질을 이용하면 CSV 데이터를 JSON으로 변환할 수 있습니다. 이 실습에서는 책 데이터를 담은 CSV 파일을 동일한 의미를 가진 JSON 형식으로 변환해 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에서 이용하기\n",
    "CSV는 파일의 크기가 작다는 장점을 갖고 있지만, 상황에 따라 JSON 같은 다른 형식으로 변환하여 주고 받아야 합니다. 책 데이터를 JSON 형식으로 변환하여 저장하는 books_to_json() 함수를 완성해 보세요.\n",
    "\n",
    "books.csv 파일은 1열부터 책의 제목, 작가의 이름, 장르, 페이지 수, 출판사 데이터를 저장하고 있습니다. 이 파일을 다음과 같은 형식의 JSON 형식으로 변환한 후, books.json 파일에 저장하세요. 페이지 수는 문자열이 아닌 정수 값이라는 것에 주의하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '...',\n",
       "  'author': '...',\n",
       "  'genre': '...',\n",
       "  'pages': Ellipsis,\n",
       "  'publisher': '...'},\n",
       " {Ellipsis},\n",
       " Ellipsis]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "  {\n",
    "    \"title\": \"...\",\n",
    "    \"author\": \"...\",\n",
    "    \"genre\": \"...\",\n",
    "    \"pages\": ...,\n",
    "    \"publisher\": \"...\"\n",
    "  },\n",
    "  {\n",
    "    ...\n",
    "  },\n",
    "  ...\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elice_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-6225b77ed961>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0melice_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEliceUtils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0melice_utils\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEliceUtils\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'elice_utils'"
     ]
    }
   ],
   "source": [
    "# CSV, JSON 모듈을 임포트합니다.\n",
    "import csv\n",
    "import json\n",
    "from elice_utils import EliceUtils\n",
    "\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "def books_to_json(src_file, dst_file):\n",
    "    # 아래 함수를 완성하세요.\n",
    "    books = []\n",
    "    with open(src_file) as src:\n",
    "        reader = csv.reader(src, delimiter = ',')\n",
    "        \n",
    "        # 각 줄 별로 대응되는 book 딕셔너리를 만듭니다.\n",
    "        for row in reader:\n",
    "            # 책 정보를 저장하는 딕셔너리를 생성합니다.\n",
    "            book = {\n",
    "                'title': row[0], \n",
    "                'author': row[1], \n",
    "                'genre': row[2], \n",
    "                'pages': int(row[3]),\n",
    "                'publisher': row[4]\n",
    "            }\n",
    "            books.append(book)\n",
    "    \n",
    "    with open(dst_file, 'w') as dst:\n",
    "        # JSON 형식으로 dst_file에 저장합니다.\n",
    "        data = json.dumps(books)\n",
    "        dst.write(data)\n",
    "\n",
    "\n",
    "\n",
    "# 아래 주석을 해제하고 결과를 확인해보세요.  \n",
    "src_file = 'books.csv'\n",
    "dst_file = 'books.json'\n",
    "books_to_json(src_file, dst_file)\n",
    "elice_utils.send_file(dst_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14차시 : 고급파이썬 - lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한 줄 함수 작성하기\n",
    "+ lambda는 def와 비슷하게 함수를 생성하는 연산입니다. 단, 함수가 이름을 갖지 않고, 특정 범위에서만 적용되기 때문에 한 번만 사용되거나 아주 간단한 함수를 선언할 때 사용됩니다. 그 외의 경우 def를 이용합니다.\n",
    "\n",
    "+ 아래 코드는 동일한 기능을 갖고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> def addition(x, y):\n",
    "        return x + y\n",
    ">>> addition(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> (lambda x, y: x + y)(10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습하기\n",
    "def로 선언된 함수를 동일한 기능을 가진 lambda 함수로 선언해 보세요. 주어진 함수와 여러분이 작성한 함수는 이름의 _ 이용하여 구분합니다.\n",
    "\n",
    "문자열이 Boolean의 자리, 즉 if나 while의 뒤에 들어갈 때 string이 빈 문자열이면 False, 아니면 True를 갖습니다.\n",
    "\n",
    "A if B else C는 B 를 만족할 경우 A, 아니면 C의 값을 가집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성공했습니다!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "num을 제곱한 값을 리턴합니다.\n",
    "'''\n",
    "def _square(num):\n",
    "    return num * num\n",
    "\n",
    "# _square()와 동일한 기능을 하는 lambda 함수 square를 만들어 보세요.\n",
    "square = lambda n : n*n\n",
    "\n",
    "'''\n",
    "string이 빈 문자열일 경우 빈 문자열을, 아니면 첫 번째 글자를 리턴합니다.\n",
    "'''\n",
    "def _first_letter(string):\n",
    "#    return string[0] if string !='' else ''\n",
    "    return string[0] if string else ''\n",
    "\n",
    "#first_letter = lambda string : '' if string != '' else string[0] \n",
    "first_letter = lambda string : string[0] if string else ''\n",
    "\n",
    "# assert를 이용하여 두 함수의 기능이 동일한 지 테스트합니다. 아래 주석을 해제하고 결과 값을 확인해보세요.\n",
    "testcases1 = [3, 10, 7, 1, -5]\n",
    "for num in testcases1:\n",
    "    assert(_square(num) == square(num))\n",
    "\n",
    "testcases2 = ['', 'hello', 'elice', 'abracadabra', '  abcd  ']\n",
    "for string in testcases2:\n",
    "    assert(_first_letter(string) == first_letter(string))\n",
    "\n",
    "# 위의 assert 테스트를 모두 통과해야만 아래의 print문이 실행됩니다.\n",
    "print(\"성공했습니다!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수를 리턴하는 함수\n",
    "+ 파이썬의 함수는 함수를 리턴값으로 가질 수 있습니다. 지금까지는 정수, 문자열과 같은 변수만을 리턴했지만, 종종 함수를 리턴값으로 갖는 경우도 있습니다.\n",
    "\n",
    "+ itemgetter() 함수가 대표적인 예입니다. itemgetter의 리턴값은 데이터의 모음을 받아 n번째 원소를 리턴하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from operator import itemgetter\n",
    ">>> get_zeroth = itemgetter(0)\n",
    ">>> numbers = [1, 2, 3]\n",
    ">>> print(get_zeroth(numbers))\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 내부에서 함수를 리턴하는 방법은, lambda를 사용할 수도 있고, 다음과 같이 함수 내에서 def를 또 사용할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "def adder(n):\n",
    "    def helper(x):\n",
    "        return x + n\n",
    "    return helper\n",
    "\n",
    "add_three = adder(3)\n",
    "print(add_three(6)) # 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석에서 이용하기\n",
    "데이터가 특정 범위에 속하는 유효한 값인지 검증하는 함수를 Validator 함수라고 부릅니다.\n",
    "\n",
    "이 실습에서는 데이터가 특정 범위의 정수값이 맞는지 확인하는 min_validator()와 max_validator() 함수를 완성해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 결과\n",
      "9세 : 유효함\n",
      "-3세 : 유효하지 않음\n",
      "7세 : 유효함\n",
      "33세 : 유효함\n",
      "18세 : 유효함\n",
      "1999세 : 유효하지 않음\n",
      "287세 : 유효하지 않음\n",
      "0세 : 유효함\n",
      "13세 : 유효함\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "주어진 값이 정수가 아니거나 최솟값 minimum보다 작으면 False를 리턴하는 함수를 리턴합니다.\n",
    "\n",
    "'''\n",
    "def min_validator(minimum):\n",
    "    def helper(n):\n",
    "        # n의 타입이 정수가 아니면 False를 리턴합니다.\n",
    "        if type(n) is not int:\n",
    "            return False\n",
    "            \n",
    "        if minimum <= n:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return helper\n",
    "    \n",
    "    \n",
    "'''    \n",
    "주어진 값이 정수가 아니거나 최댓값 maximum보다 크면 False를 리턴하는 함수를 리턴합니다.\n",
    "'''\n",
    "def max_validator(maximum):\n",
    "    def helper(n):\n",
    "        # n의 타입이 정수가 아니면 False를 리턴합니다.\n",
    "        if type(n) is not int:\n",
    "            return False\n",
    "        if n > maximum:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    return helper\n",
    "\n",
    "\n",
    "def validate(n, validators):\n",
    "    # validator 중 하나라도 통과하지 못하면 False를 리턴합니다.\n",
    "    for validator in validators:\n",
    "        if not validator(n):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# 작성한 함수를 테스트합니다. # 아래 주석을 해제하고 결과 값을 확인해보세요.\n",
    "# # 나이 데이터를 검증하는 validator를 선언합니다. \n",
    "age_validators = [min_validator(0), max_validator(120)]\n",
    "ages = [9, -3, 7, 33, 18, 1999, 287, 0, 13]\n",
    "\n",
    "# 주어진 나이 데이터들에 대한 검증 결과를 출력합니다.\n",
    "print(\"검증 결과\")\n",
    "for age in ages:\n",
    "    result = \"유효함\" if validate(age, age_validators) else \"유효하지 않음\"\n",
    "    print(\"{}세 : {}\".format(age, result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15차시 : 고급 파이썬 - map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리스트에 함수 적용하기\n",
    "map()은 데이터 구조의 각 원소들에 동일한 함수를 적용하여 새로운 데이터를 만드는 파이썬의 기본 함수입니다. data라는 리스트가 주어졌을 때, 아래의 두 코드는 유사한 연산을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-c45d6f817880>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    ">>> [func(x) for x in data]\n",
    ">>> map(func, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehension과 map()의 가장 주된 차이점은 연산을 진행하는 시점입니다. map()의 경우 데이터를 map이라는 클래스로 저장하고, 데이터가 필요해질 때 주어진 연산을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습하기\n",
    "앞서 보았던 books.csv 파일을 읽어서 제목의 리스트를 리턴하는 get_titles() 함수를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundamentals of Wavelets\n",
      "Data Smart\n",
      "God Created the Integers\n",
      "Superfreakonomics\n",
      "Orientalism\n",
      "Nature of Statistical Learning Theory, The\n",
      "Integration of the Indian States\n",
      "Drunkard's Walk, The\n",
      "Image Processing & Mathematical Morphology\n",
      "How to Think Like Sherlock Holmes\n",
      "Data Scientists at Work\n",
      "Slaughterhouse Five\n",
      "Birth of a Theorem\n",
      "Structure & Interpretation of Computer Programs\n",
      "Age of Wrath, The\n",
      "Trial, The\n",
      "Statistical Decision Theory'\n",
      "Data Mining Handbook\n",
      "New Machiavelli, The\n",
      "Physics & Philosophy\n",
      "Making Software\n",
      "Analysis, Vol I\n",
      "Machine Learning for Hackers\n",
      "Signal and the Noise, The\n",
      "Python for Data Analysis\n",
      "Introduction to Algorithms\n",
      "Beautiful and the Damned, The\n",
      "Outsider, The\n",
      "Complete Sherlock Holmes, The - Vol I\n",
      "Complete Sherlock Holmes, The - Vol II\n",
      "Wealth of Nations, The\n",
      "Pillars of the Earth, The\n",
      "Mein Kampf\n",
      "Tao of Physics, The\n",
      "Surely You're Joking Mr Feynman\n",
      "Farewell to Arms, A\n",
      "Veteran, The\n",
      "False Impressions\n",
      "Last Lecture, The\n",
      "Return of the Primitive\n",
      "Jurassic Park\n",
      "Russian Journal, A\n",
      "Tales of Mystery and Imagination\n",
      "Freakonomics\n",
      "Hidden Connections, The\n",
      "Story of Philosophy, The\n",
      "Asami Asami\n",
      "Journal of a Novel\n",
      "Once There Was a War\n",
      "Moon is Down, The\n",
      "Brethren, The\n",
      "In a Free State\n",
      "Catch 22\n",
      "Complete Mastermind, The\n",
      "Dylan on Dylan\n",
      "Soft Computing & Intelligent Systems\n",
      "Textbook of Economic Theory\n",
      "Econometric Analysis\n",
      "Learning OpenCV\n",
      "Data Structures Using C & C++\n",
      "Computer Vision, A Modern Approach\n",
      "Principles of Communication Systems\n",
      "Let Us C\n",
      "Amulet of Samarkand, The\n",
      "Crime and Punishment\n",
      "Angels & Demons\n",
      "Argumentative Indian, The\n",
      "Sea of Poppies\n",
      "Idea of Justice, The\n",
      "Raisin in the Sun, A\n",
      "All the President's Men\n",
      "Prisoner of Birth, A\n",
      "Scoop!\n",
      "Ahe Manohar Tari\n",
      "Last Mughal, The\n",
      "Social Choice & Welfare, Vol 39 No. 1\n",
      "Radiowaril Bhashane & Shrutika\n",
      "Gun Gayin Awadi\n",
      "Aghal Paghal\n",
      "Maqta-e-Ghalib\n",
      "Beyond Degrees\n",
      "Manasa\n",
      "India from Midnight to Milennium\n",
      "World's Greatest Trials, The\n",
      "Great Indian Novel, The\n",
      "O Jerusalem!\n",
      "City of Joy, The\n",
      "Freedom at Midnight\n",
      "Winter of Our Discontent, The\n",
      "On Education\n",
      "Free Will\n",
      "Bookless in Baghdad\n",
      "Case of the Lame Canary, The\n",
      "Theory of Everything, The\n",
      "New Markets & Other Essays\n",
      "Electric Universe\n",
      "Hunchback of Notre Dame, The\n",
      "Burning Bright\n",
      "Age of Discontuinity, The\n",
      "Doctor in the Nude\n",
      "Down and Out in Paris & London\n",
      "Identity & Violence\n",
      "Beyond the Three Seas\n",
      "World's Greatest Short Stories, The\n",
      "Talking Straight\n",
      "Maugham's Collected Short Stories, Vol 3\n",
      "Phantom of Manhattan, The\n",
      "Ashenden of The British Agent\n",
      "Zen & The Art of Motorcycle Maintenance\n",
      "Great War for Civilization, The\n",
      "We the Living\n",
      "Artist and the Mathematician, The\n",
      "History of Western Philosophy\n",
      "Selected Short Stories\n",
      "Rationality & Freedom\n",
      "Clash of Civilizations and Remaking of the World Order\n",
      "Uncommon Wisdom\n",
      "One\n",
      "Karl Marx Biography\n",
      "To Sir With Love\n",
      "Half A Life\n",
      "Discovery of India, The\n",
      "Apulki\n",
      "Unpopular Essays\n",
      "Deceiver, The\n",
      "Veil: Secret Wars of the CIA\n",
      "Char Shabda\n",
      "Rosy is My Relative\n",
      "Moon and Sixpence, The\n",
      "Political Philosophers\n",
      "Short History of the World, A\n",
      "Trembling of a Leaf, The\n",
      "Doctor on the Brain\n",
      "Simpsons & Their Mathematical Secrets\n",
      "Pattern Classification\n",
      "From Beirut to Jerusalem\n",
      "Code Book, The\n",
      "Age of the Warrior, The\n",
      "Final Crisis\n",
      "Killing Joke, The\n",
      "Flashpoint\n",
      "Batman Earth One\n",
      "Crisis on Infinite Earths\n",
      "Numbers Behind Numb3rs, The\n",
      "Superman Earth One - 1\n",
      "Superman Earth One - 2\n",
      "Justice League: Throne of Atlantis\n",
      "Justice League: The Villain's Journey\n",
      "Death of Superman, The\n",
      "History of the DC Universe\n",
      "Batman: The Long Halloween\n",
      "Life in Letters, A\n",
      "Information, The\n",
      "Journal of Economics, vol 106 No 3\n",
      "Elements of Information Theory\n",
      "Power Electronics - Rashid\n",
      "Power Electronics - Mohan\n",
      "Neural Networks\n",
      "Grapes of Wrath, The\n",
      "Vyakti ani Valli\n",
      "Statistical Learning Theory\n",
      "Empire of the Mughal - The Tainted Throne\n",
      "Empire of the Mughal - Brothers at War\n",
      "Empire of the Mughal - Ruler of the World\n",
      "Empire of the Mughal - The Serpent's Tooth\n",
      "Empire of the Mughal - Raiders from the North\n",
      "Mossad\n",
      "Jim Corbett Omnibus\n",
      "20000 Leagues Under the Sea\n",
      "Batatyachi Chal\n",
      "Hafasavnuk\n",
      "Urlasurla\n",
      "Pointers in C\n",
      "Cathedral and the Bazaar, The\n",
      "Design with OpAmps\n",
      "Think Complexity\n",
      "Devil's Advocate, The\n",
      "Ayn Rand Answers\n",
      "Philosophy: Who Needs It\n",
      "World's Great Thinkers, The\n",
      "Data Analysis with Open Source Tools\n",
      "Broca's Brain\n",
      "Men of Mathematics\n",
      "Oxford book of Modern Science Writing\n",
      "Justice, Judiciary and Democracy\n",
      "Arthashastra, The\n",
      "We the People\n",
      "We the Nation\n",
      "Courtroom Genius, The\n",
      "Dongri to Dubai\n",
      "History of England, Foundation\n",
      "City of Djinns\n",
      "India's Legal System\n",
      "More Tears to Cry\n",
      "Ropemaker, The\n",
      "Angels & Demons\n",
      "Judge, The\n",
      "Attorney, The\n",
      "Prince, The\n",
      "Eyeless in Gaza\n",
      "Tales of Beedle the Bard\n",
      "Girl with the Dragon Tattoo\n",
      "Girl who kicked the Hornet's Nest\n",
      "Girl who played with Fire\n",
      "Batman Handbook\n",
      "Murphy's Law\n",
      "Structure and Randomness\n",
      "Image Processing with MATLAB\n",
      "Animal Farm\n",
      "Idiot, The\n",
      "Christmas Carol, A\n"
     ]
    }
   ],
   "source": [
    "# CSV 모듈을 임포트합니다.\n",
    "import csv\n",
    "\n",
    "def get_titles(books_csv):\n",
    "    with open(books_csv) as books:\n",
    "        reader = csv.reader(books, delimiter=',')\n",
    "        # 함수를 완성하세요.\n",
    "        get_title = lambda row: row[0]\n",
    "        titles = map(get_title, reader)\n",
    "        return list(titles)\n",
    "\n",
    "\n",
    "# 작성한 코드를 테스트합니다. 주석을 해제하고 실행하세요.\n",
    "books = 'books.csv'\n",
    "titles = get_titles(books)\n",
    "for title in titles:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16차시 : 고급 파이썬 filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리스트에 함수 적용하기\n",
    "+ filter()는 주어진 데이터 구조에서 특정 조건을 만족하는 원소만 골라 내는 파이썬의 기본 함수입니다. data라는 리스트가 주어졌을 때, 아래의 두 코드는 유사한 연산을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-ac33ff3de624>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "[x for x in data if func(x)]\n",
    "filter(func, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter()도 map()과 마찬가지로 즉시 연산되지 않고 filter 타입의 데이터 구조를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습하기\n",
    "books.csv 파일을 읽어서 페이지 수가 250이 넘는 책들의 제목을 리스트로 리턴하는 get_titles_of_long_books() 함수를 완성하세요.\n",
    "\n",
    "Tips!\n",
    "map()과 filter() 모두 사용 방법은 동일하지만 filter()의 경우 인자로 가지는 함수의 결과가 참인지 거짓인지에 따라, 해당 요소를 포함할지를 결정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV 모듈을 임포트합니다.\n",
    "import csv\n",
    "\n",
    "def get_titles_of_long_books(books_csv):\n",
    "    with open(books_csv) as books:\n",
    "        reader = csv.reader(books, delimiter=',')\n",
    "        # 함수를 완성하세요.\n",
    "        is_long = lambda row: int(row[3]) > 250\n",
    "        get_title = lambda row: row[0]\n",
    "        \n",
    "        long_books = filter(is_long, reader)\n",
    "        long_book_titles = map(get_title, long_books)\n",
    "        \n",
    "        return list(long_book_titles)\n",
    "\n",
    "\n",
    "# 작성한 함수를 테스트합니다. 주석을 해제하고 실행하세요.\n",
    "books  = 'books.csv'\n",
    "titles = get_titles_of_long_books(books)\n",
    "for title in titles:\n",
    "    print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](Pictures/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2](Pictures/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3](Pictures/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4](Pictures/4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'nbconvert,'\n"
     ]
    }
   ],
   "source": [
    "pip install nbconvert, pandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipynb-py-convert\n",
      "  Downloading ipynb-py-convert-0.4.6.tar.gz (3.9 kB)\n",
      "Building wheels for collected packages: ipynb-py-convert\n",
      "  Building wheel for ipynb-py-convert (setup.py): started\n",
      "  Building wheel for ipynb-py-convert (setup.py): finished with status 'done'\n",
      "  Created wheel for ipynb-py-convert: filename=ipynb_py_convert-0.4.6-py3-none-any.whl size=4629 sha256=0d446ccac70afd0b634b96a0b1e6ab88a5857ee1f52cd8f94ddeee4788768fb1\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\49\\ee\\0a\\ff1f946e7969e39aec10a28d84692859084219f27d2ae35119\n",
      "Successfully built ipynb-py-convert\n",
      "Installing collected packages: ipynb-py-convert\n",
      "Successfully installed ipynb-py-convert-0.4.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipynb-py-convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert in c:\\users\\administrator\\anaconda3\\lib\\site-packages (6.0.7)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (0.6.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (2.7.2)\n",
      "Requirement already satisfied: jinja2>=2.4 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (2.11.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (0.3)\n",
      "Requirement already satisfied: nbformat>=4.4 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (5.0.8)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (1.4.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (0.5.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (0.1.2)\n",
      "Requirement already satisfied: testpath in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (0.4.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: bleach in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (3.2.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (4.6.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbconvert) (5.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from jinja2>=2.4->nbconvert) (1.1.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbformat>=4.4->nbconvert) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbformat>=4.4->nbconvert) (0.2.0)\n",
      "Requirement already satisfied: async-generator in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (1.4.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (6.1.7)\n",
      "Requirement already satisfied: webencodings in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from bleach->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from bleach->nbconvert) (20.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from bleach->nbconvert) (1.15.0)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from jupyter-core->nbconvert) (227)\n",
      "Requirement already satisfied: setuptools in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (50.3.1.post20201107)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (20.3.0)\n",
      "Requirement already satisfied: tornado>=4.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (6.0.4)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (19.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from packaging->bleach->nbconvert) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
